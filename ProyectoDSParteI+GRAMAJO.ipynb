{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ***PRÁCTICO FINAL DE CIENCIA DE DATOS I - Coder House***\n",
        "Estudiante: **Gonzalo Leonel Gramajo**  \n",
        "Comisión: **74920**  \n",
        "Documento: **40441349**  \n",
        "Año: **2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "____________________________________________________________________________________________\n",
        "## **1. INTRODUCCIÓN Y OBJETIVO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIpXt0uytTfw"
      },
      "source": [
        "Este notebook corresponde al trabajo final del curso \"Fundamentos de ciencia de datos\" de Coder House. Está basado en un dataset de ventas de autos rescatado desde Keegle. Este conjunto de datos incluye todas las entradas de vehículos usados ​​dentro de los Estados Unidos en Craigslist.com.\n",
        "Es importante resaltar que se cuenta con 426 mil lineas y el archivo ocupa 1.45 GB de almacenamiento, por lo que un archivo de tal tamaño no se peude subir a GitHub. Dado esto, el archivo .csv se puede encontrar disponible en Google Drive y obviamente, Kaggle.\n",
        "\n",
        "### **Dataset**\n",
        "Used Cars Dataset - Vehicles listings from Craigslist.org.  \n",
        "Enlace web a Kaggle: https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data  \n",
        "Enlace web a Google Drive: https://drive.google.com/file/d/1uQ_YhqBimI46j5W-EgSwkjZvpFt87ejt/view?usp=sharing\n",
        "\n",
        "### **Objetivo**\n",
        "*Mediante el uso de algortimos de aprendizaje automático, lograr predecir el precio de venta de los vehículos según los datos de entrada odómetro (kilometraje), year (año de fabricación), transmission (trasmisión), fuel (combustible).*\n",
        "\n",
        "**Pasos para lograr el objetivo:**\n",
        "1.  **Introducción y Objetivo:** Definir el problema y el objetivo.\n",
        "2.  **Importar Librerías:** Cargar las herramientas necesarias.\n",
        "3.  **Carga de Datos:** Leer el dataset.\n",
        "4.  **Hipótesis:** Plantear una hipótesis clara.\n",
        "5.  **Análisis Exploratorio de Datos (EDA):** Entender los datos, distribuciones, valores faltantes y relaciones.\n",
        "6.  **Feature Engineering (Ingeniería de Características):** Crear nuevas características si es relevante.\n",
        "7.  **Preprocesamiento de Datos:** Preparar los datos para el modelo (manejo de categorías, escalado).\n",
        "8.  **División de Datos:** Separar en conjuntos de entrenamiento y prueba.\n",
        "9.  **Construcción y Entrenamiento del Modelo:** Usar RandomForestClassifier.\n",
        "10. **Evaluación del Modelo:** Medir el rendimiento con métricas adecuadas.\n",
        "11. **Análisis de Importancia de Características:** Identificar qué variables son más influyentes.\n",
        "12. **Conclusiones:** Interpretar los resultados y validar/refutar la hipótesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___________________________________________________________________________________________\n",
        "## **2. IMPORTACIÓN DE MÓDULOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para cargar todos los módulos (herramientas) que se necesitan en el despliegue de todo el análisis y entrenamiento, se debe ejecutar el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Herramientas principales\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Módulos de visualización\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Módulo de preprocesamiento\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Módulo de división de datos\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Módulo de regresión\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Módulo de evaluación\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rizCDcNeVwSv"
      },
      "source": [
        "___________________________________________________________________________________________\n",
        "## **3. CARGA DE DATOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para conseguir un dataframe de los datos que contiene el .csv del dataset rescatado, se debe ejecutar el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "CTe0LMjZtCSL",
        "outputId": "332cc139-55c3-4f8e-81f8-ff03e9cd6526"
      },
      "outputs": [],
      "source": [
        "file_path = './vehicles.csv' # ruta al archivo CSV\n",
        "df = pd.read_csv(file_path) # leer el archivo CSV y conseguir un dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(10) # mostrar los primeros 5 valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.tail(10) # mostrar los últimos 5 valores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfCZNtLizh9H"
      },
      "source": [
        "_____________________________________________________________________________\n",
        "## **4. HIPÓTESIS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las siguientes hipótesis se plantean en marco al objetivo general de este análisis:  \n",
        "\n",
        "1. **Los vehículos con valores en el odómetro más bajo se venden exponencialmente más caros.**  \n",
        "*Esto es porque los vehículos con menos kilometraje (en teoría) deberían estar mas nuevos y en mejor estado que los autos que recorrieron más kilometros. En base a esto, se hipotetiza que la variación de este precio es de tipo exponencial.*  \n",
        "  \n",
        "2. **Los vehículos con año de fabricación menor, se venden exponencialmente más caros.**  \n",
        "*Siguiendo con la premisa de que los autos más nuevos valen exponencialmente menos, se tratará de comprobar si esto también va en función del año de fabricación del vehículo y que correlación existe con la hipótesis anterior.*  \n",
        "\n",
        "3. **Más del 50% de las publicaciones, son de vehículos con transmisión automática.**  \n",
        "*Teniendo en cuenta la premisa que los automóviles con trasmisión automática son los más valuados, se verificará si esto es efectivamente así y que relación tiene con las 2 hipótesis anteriores.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **5. ANÁLISIS EXPLORATORIO DE LOS DATOS (EDA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Verificar la integridad de los datos en las columnas. Esto se hace para verificar que tan buena es la calidad del dataset. Keggle, la pagina web desde donde se descargo el datase, muestra un reporte de la integridad de los datos de cada columna, pero para complementar el análisis, se realiza el siguiente codigo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para calcular el porcentaje de integridad de cada columna\n",
        "def column_integrity_simple(df):\n",
        "    for col in df.columns:\n",
        "        total_rows = len(df)\n",
        "        non_null_count = df[col].notna().sum()\n",
        "        integrity_percentage = (non_null_count / total_rows) * 100\n",
        "        print(f\"Columna {col}: {round(integrity_percentage, 2)}% -> {total_rows - non_null_count}/{total_rows}\")\n",
        "\n",
        "# Ejecutar el análisis de integridad simple\n",
        "print(\"Integridad de los datos por columna:\")\n",
        "column_integrity_simple(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Debido a que se muestra que no todas las columnas están completas, con el 100% de los datos, es interesante saber que cantidad de datos falta. Para esto se ejecuta la siguiente línea de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Si se quiere observar lo contrario, es decir, que datos son no nulos, además de que tipo de datos son y el uso de memoria del dataframe, conviene ejecutar la siguiente linea de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Por ultimo, para tener un pantallazo de alguno valores impotantes como la tendecnia central, dispersión y forma de la distribución de los datos, exluyendo los valores NaN, se debe ejecutar la siguiente linea de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Descripción de los campos\n",
        "\n",
        "| # | CAMPO | TIPO DE DATO | DESCRIPCIÓN |\n",
        "|---|-------|--------------|-------------|\n",
        "| 1 | id | number | identificador del automovil publicado en la pagina web. |\n",
        "| 2 | url | string | direccion web a la publicaciion del automovil en la pagina web. |\n",
        "| 3 | region | string | estado de los estado unidos donde esta publicado el automovil segun Craiglist. |\n",
        "| 4 | region_url | string | url pertencceinte exclusivamente a la region. |\n",
        "| 5 | price | number | precio del automovil en unidades de la moneda dolar (USD). |\n",
        "| 6 | year | number | año de fabricacion del automovil. |\n",
        "| 7 | manufacturer | string |fabricante del vehiculo. |\n",
        "| 8 | model | string | modelo del vehiculo segun la disignacion que le dio el fabricante. |\n",
        "| 9 | condicion | string | esta es una evaluacion que se hace al publicar el automovil en la pagina web, pero es un dato subjetivo acorde al publicador. |\n",
        "| 10 | cylinders | string | cantidad de cilindros que tiene el motor en su estructura y como estan configurados. |\n",
        "| 11 | fuel | string | combustible que utiliza el vehiculo. |\n",
        "| 12 | odometer | number | es la distancia recorrida todal del vehiculo en millas. |\n",
        "| 13 | title_status | string | estado del titulo del vehiculo. No se conoce especificamente que significa, se averiguara mas al respecto. |\n",
        "| 14 | transmission | string | tipo de trasmision con la que esta configurado el vehiculo. |\n",
        "| 15 | VIN | string | numero de identificacion del vehiculo. Es parecido a la patente. |\n",
        "| 16 | drive | string | tipo de traccion del vehiculo. Esto es, como se distribuye la energia mecanica a las ruedas. |\n",
        "| 17 | size | number | se invertigara mas al respecto de que significa esta columna. |\n",
        "| 18 | type | string | tipo o categoria del formato del vehiculo. |\n",
        "| 19 | paint_color | string | color exterior del vehiculo. |\n",
        "| 20 | image_url | string | link a la imagen del vehiculo publicado. |\n",
        "| 21 | description | string | descripcion del vehiculo redactada por la persona que publico el vehiculo en la pagina web. |\n",
        "| 22 | country | null | columna vacia ya que el valor siempre era estados unidos. |\n",
        "| 23 | state | string | estado de los estados unidos donde se publica el vehiculo. No se almacena el nombre completo, sino la abreviatura. |\n",
        "| 24 | lat | number | latitud de la ubicacion del vehiculo listado. |\n",
        "| 25 | lon | number | longitud de la ubicacion del vehiculo listado. |\n",
        "| 26 | posting_date | datetime | fecha de la publicacion del vehiculo. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Debido a que existen datos que no se encuentran en el dataframe, se procede a completar los mismos con datos acordes al tipo que corresponde. Esto se hace con el fin de evitar errores en los proximos pasos (graficos, modelado). También es importante porque se puede completar una linea en vez de eliminarla totalmente y perder todos esos datos.  \n",
        "\n",
        "Por otro lado, el dataframe tiene datos que no se usarán y es conveniente elimarlos para ahorrar espacio en memoria y agilizar el procesamiento. Si no fuesen muchos datos, esto tal vez no es necesario de realizar, a pesar de que se pierde prolijidad. Pero como estamos hablando de mas de un dataframe de más de 1 GB, se debe optimizar esto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Completar datos faltantes en las columnas de tipo object/string\n",
        "columnas_editar = (\"manufacturer\", \"model\", \"condition\",\n",
        "                   \"cylinders\", \"fuel\", \"title_status\",\n",
        "                   \"transmission\", \"drive\", \"size\", \"type\",\n",
        "                   \"paint_color\")\n",
        "for columna in columnas_editar:\n",
        "    df[columna] = df[columna].fillna(\"uknown\")\n",
        "\n",
        "# Completar datos faltantes en la columna descripción con strings vacíos\n",
        "df[\"description\"] = df[\"description\"].fillna(\"\")\n",
        "\n",
        "# Completamos los datos faltantes en las columnas de tipo number\n",
        "df[\"year\"] = df[\"year\"].fillna(df[\"year\"].mean())\n",
        "df[\"odometer\"] = df[\"odometer\"].fillna(df[\"odometer\"].mean())\n",
        "\n",
        "# Eliminamos columnas innecesarias\n",
        "columnas_eliminar = [\"url\",\"region\", \"VIN\", \"county\", \"lat\", \"long\", \"image_url\", \"region_url\", \"posting_date\"]\n",
        "df.drop(columns=columnas_eliminar, axis=1, inplace=True)\n",
        "\n",
        "# Mostrar cuántos datos faltantes quedan\n",
        "print(df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay columnas que no fueron completadas porque no es necesario hacerlo por el tipo de dato que representan. Por ejemplo, VIN es la patente o un identificador unico del vehoiculo. Sin embargo, no son datos que sean relevantes para la contrastación de la hipotesis y no serán usados en el análisis o entrenamiento. Como así tambien la ubicacion precisa de donde se realizo el posteo, es decir \"lat\" y \"lon\".  \n",
        "Luego de estos cambios, el dataframe queda con la siguiente descripción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **5.1. CONTRASTACIÓN DE LAS HIPÓTESIS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9IIKsIOxR9s"
      },
      "source": [
        "#### Hipótesis 1:\n",
        "*''Los vehículos con valores en el odómetro más bajo se venden exponencialmente más caros.''*\n",
        "\n",
        "Primero, se puede visualizar los datos de precio contra el odometro para poder visualizar si a simple vista, la relacion es exponencial como se plantea en la hipótesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se realiza el siguiente filtrado para poder eliminar un poco los outliers y los datos que no tienen sentido.\n",
        "df_filtrado = df[\n",
        "    (df[\"odometer\"] < df[\"odometer\"].quantile(0.98)) &\n",
        "    (df[\"price\"] < df[\"price\"].quantile(0.98)) &\n",
        "    (df[\"price\"] > 1000)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_filtrado, x=\"odometer\", y=\"price\", alpha=0.3, s=10)\n",
        "plt.title(\"Relación entre odómetro y precio del vehículo\")\n",
        "plt.xlabel(\"Odómetro (millas)\")\n",
        "plt.ylabel(\"Precio (USD)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por la cantidad inmensa de puntos (426.000 datos), parece una nebulosa y no se percibe claramente si la relación es exponencial, lineal o de otro tipo. Se puede afirmar que hay mucha dispersión de los datos.  \n",
        "Desde ya, como **conclusión**, se puede afirmar que el odómetro solo NO explica el precio de forma clara ni de forma exponencial. Puede haber una tendencia débil, pero no es dominante.  \n",
        "Sí se podría filtrar los datos por marca, año o modelo para mostrar una tendecnia menos general. Para observar esto, se debe ejecutar el siguiente codigo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty4zW7FdwHko",
        "outputId": "e7dcd895-908c-4329-e617-5b7bdf2709f8"
      },
      "outputs": [],
      "source": [
        "# Contar las marcas\n",
        "marca_mas_publicada = df_filtrado[\"manufacturer\"].value_counts().idxmax()\n",
        "print(f\"La marca con más publicaciones es: {marca_mas_publicada}\")\n",
        "\n",
        "# Filtrar solo esa marca\n",
        "df_marca = df_filtrado[df_filtrado[\"manufacturer\"] == marca_mas_publicada]\n",
        "\n",
        "# Contar los modelos\n",
        "modelo_mas_publicado = df_marca[\"model\"].value_counts().idxmax()\n",
        "print(f\"Modelo de la marca con más publicaciones: {modelo_mas_publicado}\")\n",
        "\n",
        "# Filtrar solo ese modelo\n",
        "df_marca_modelo = df_marca[df_marca[\"model\"] == modelo_mas_publicado]\n",
        "\n",
        "# Mostrar la relación entre el precio y el odómetro para esa marca\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_marca_modelo, x=\"odometer\", y=\"price\", alpha=0.3, s=10)\n",
        "plt.title(f\"Relación odómetro vs precio - {marca_mas_publicada} {modelo_mas_publicado}\")\n",
        "plt.xlabel(\"Odómetro (millas)\")\n",
        "plt.ylabel(\"Precio (USD)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora si se puede ver una clara tendencia aunque hay una gran cantdad de outliers que podrían afectar el posterior modelado. La dispersión que se vé muestra mas bien una distribución lineal con pendiente negativa. Por lo tanto la hipóteisis queda refutada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hipótesis 2:\n",
        "*''Los vehículos con año de fabricación menor, se venden exponencialmente más caros.''*\n",
        "\n",
        "Primero, se puede visualizar los datos de precio contra los años para poder visualizar si a simple vista, la relacion es exponencial como se plantea en la hipótesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se realiza el siguiente filtrado para poder eliminar un poco los outliers y los datos que no tienen sentido.\n",
        "df_filtrado = df[\n",
        "    (df[\"year\"] < df[\"year\"].quantile(0.99)) &\n",
        "    (df[\"price\"] < df[\"price\"].quantile(0.99)) &\n",
        "    (df[\"price\"] > 1000)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar las marcas\n",
        "marca_mas_publicada = df_filtrado[\"manufacturer\"].value_counts().idxmax()\n",
        "print(f\"La marca con más publicaciones es: {marca_mas_publicada}\")\n",
        "\n",
        "# Filtrar solo esa marca\n",
        "df_marca = df_filtrado[df_filtrado[\"manufacturer\"] == marca_mas_publicada]\n",
        "\n",
        "# Contar los modelos\n",
        "modelo_mas_publicado = df_marca[\"model\"].value_counts().idxmax()\n",
        "print(f\"Modelo de la marca con más publicaciones: {modelo_mas_publicado}\")\n",
        "\n",
        "# Filtrar solo ese modelo\n",
        "df_marca_modelo = df_marca[df_marca[\"model\"] == modelo_mas_publicado]\n",
        "\n",
        "# Mostrar la relación entre el precio y el odómetro para esa marca\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_marca_modelo, x=\"year\", y=\"price\", alpha=0.3, s=10)\n",
        "plt.title(f\"Relación año vs precio - {marca_mas_publicada} {modelo_mas_publicado}\")\n",
        "plt.xlabel(\"Año\")\n",
        "plt.ylabel(\"Precio (USD)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso se nota que si se cumple lo que se plantea la hipótesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hipótesis 3:\n",
        "*''Más del 50% de las publicaciones, son de vehículos con transmisión automática.''*\n",
        "\n",
        "Se puede visualizar los datos en gráfico de torta para saber facilmente si esto es cierto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar los valores de la columna \"transmission\"\n",
        "conteo_transmision = df_filtrado[\"transmission\"].value_counts()\n",
        "\n",
        "# Mostrar los conteos (opcional, para ver qué hay)\n",
        "print(conteo_transmision)\n",
        "\n",
        "# Gráfico de torta\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(\n",
        "    conteo_transmision,\n",
        "    labels=conteo_transmision.index,\n",
        "    autopct='%1.1f%%',  # Muestra el porcentaje\n",
        "    startangle=180,       # Para que empiece arriba\n",
        "    shadow=False\n",
        ")\n",
        "plt.title(\"Distribución de tipos de transmisión\")\n",
        "plt.axis('equal')  # Hace que el círculo sea redondo\n",
        "plt.show()\n",
        "\n",
        "# Además, calculamos el porcentaje de \"automatic\"\n",
        "total = conteo_transmision.sum()\n",
        "automaticos = conteo_transmision.get(\"automatic\", 0)\n",
        "\n",
        "porcentaje_automaticos = (automaticos / total) * 100\n",
        "print(f\"Porcentaje de vehículos automáticos: {porcentaje_automaticos:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta ocasión, tambien queda demostrada la hipótesis, ya que el 78,88% de los vehículos son con transmisión automática."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **6. FEATURE ENGINEERING (Ingeniería de características)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se pudo ver en las hipótesis, los datos tienen una gran dispersión y muchos outliers. Esto es perjudicial para el modelo, por lo que se filtrarán los datos outliers para lograr un modelo más fiable. Para eso se debe ejecutar el siguiente codigo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[\n",
        "    (df[\"odometer\"] < df[\"odometer\"].quantile(0.98)) &\n",
        "    (df[\"year\"] >= 1960) &\n",
        "    (df[\"year\"] <= 2024) &\n",
        "    (df[\"price\"] > 1000) &\n",
        "    (df[\"price\"] < df[\"price\"].quantile(0.98))\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se crearán las siguientes nuevas caracterísitcas para poder lograr un entrenamiento factible que logre el objetivo:  \n",
        "\n",
        "1. **Antigüedad del vehículo:** esta característica logra un valor que es más intuitivo que el año. A mayor edad, menor precio.\n",
        "2. **Kilometraje promedio por año:** esta nueva característica da idea del uso intensivo. Un auto más antigüo pero poco usado puede valer más que uno nuevo con mucho kilometraje.\n",
        "3. **Densidad de publicaciones por estado:** esto mide cuántos autos hay por estado. En base a esto se puede deducir como afecta la ley de oferta/demanda.\n",
        "4. **Longitud del texto de descripción:** En ventas, una descripción larga a veces significa más detalle, más confianza del vendedor, por lo tanto esto podría afectar al precio de venta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Antigüedad del vehículo\n",
        "df[\"vehicle_age\"] = 2025 - df[\"year\"]\n",
        "# Kilometraje promedio por año\n",
        "df[\"miles_per_year\"] = df[\"odometer\"] / df[\"vehicle_age\"]\n",
        "# Densidad de publicaciones por estado\n",
        "state_counts = df[\"state\"].value_counts().to_dict()\n",
        "df[\"state_density\"] = df[\"state\"].map(state_counts)\n",
        "# Longitud del texto de descripción\n",
        "df[\"desc_length\"] = df[\"description\"].apply(lambda x: len(str(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez ejecutado este código, el dataframe queda como sigue:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n",
        "df.head()   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **7. PREPROCESAMIENTO DE DATOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con respecto a este paso, en primer lugar se aborda el manejo de las variables categóricas. Esto se hace porque lo que se busca es predecir el precio de un vehículo. Por lo tanto, se estaría hablando de problema de regresión ya que, el precio, es un valor numérico contínuo.  \n",
        "\n",
        "Cuando el problema es de este tipo, las variables categoricas que tiene el modelo se deben pasar a variables numéricas. Para esto se utilizará la técnica Label Encoding, que consiste en asignar un numero a cada categoría de los campos categóricos presentes en el dataset y que son importantes para el entrenamiento del modelo predictivo.  \n",
        "\n",
        "Es importante aclarar también que, dada la cantidad de variables a disposición, afectarían al precio que se predice. Por lo tanto, se hace uso de un algoritmo del tipo \"Árbol de regresión\", más precisamente el algoritmo **RandomForestRegressor**. El \"Forest\" del nombre quiere decir que Random Forest combina muchos árboles diferentes y toma el promedio de sus predicciones, lo que reduce el sobreajuste y mejora la precisión respecto a usar un solo árbol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iniciar instancia del codificador\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Codificación de las columnas categóricas\n",
        "df['transmission_encoded'] = label_encoder.fit_transform(df['transmission'])\n",
        "df['manufacturer_encoded'] = label_encoder.fit_transform(df['manufacturer'])\n",
        "df['model_encoded'] = label_encoder.fit_transform(df['model'])\n",
        "df['type_encoded'] = label_encoder.fit_transform(df['type'])\n",
        "df['fuel_encoded'] = label_encoder.fit_transform(df['fuel'])\n",
        "\n",
        "# Mostrar información del DataFrame después de la codificación\n",
        "print(\"\\nInformación del DataFrame después de la codificación:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **8. DIVISIÓN DE DATOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se procede a dividir el conjunto de datos en los correspondientes al entrenamiento y los de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición de variables predictoras (X) y variable objetivo (y)\n",
        "\n",
        "X = df[[ # Variables predictoras\n",
        "    'transmission_encoded',\n",
        "    'manufacturer_encoded',\n",
        "    'model_encoded',\n",
        "    'type_encoded',\n",
        "    'fuel_encoded',\n",
        "    'miles_per_year',\n",
        "    'vehicle_age',\n",
        "    'state_density',\n",
        "    'desc_length']]\n",
        "\n",
        "y = df['price']  # Columna que se va a predecir\n",
        "\n",
        "# Dividimos en 80% entrenamiento y 20% prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **9. CONSTRUCCIÓN Y ENTRENAMIENTO DEL MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instanciar el modelo\n",
        "# n_estimators: número de árboles en el bosque\n",
        "# random_state: semilla para la aleatoriedad (reproducibilidad)\n",
        "modelo = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "modelo.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **10. EVALUACIÓN DEL MODELO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se usan las 3 métricas más comunes para modelos de regresión, es decir:\n",
        "\n",
        "- **MAE (Mean Absolute Error)**: cuánto se equivoca el modelo en promedio, sin importar el signo.\n",
        "- **RMSE (Root Mean Squared Error)**: penaliza más los errores grandes.\n",
        "- **R² (coeficiente de determinación)**: qué proporción de la variabilidad del precio explica el modelo (1 = perfecto, 0 = no explica nada)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hacemos predicciones sobre el conjunto de prueba\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estas metricas nos quiere decir que:\n",
        "1. El modelo se equivoca en promedio por $1.755, un error muy bajo y aceptable.\n",
        "2. Los errores grandes son penalizados más; aun así, sigue siendo bajo.\n",
        "3. El modelo explica el 91% de la variabilidad del precio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
        "plt.xlabel('Precio real')\n",
        "plt.ylabel('Precio predicho')\n",
        "plt.title('Comparación: Precio real vs. Precio predicho')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **11. ANÁLISIS DE IMPORTANCIA DE CARACTERÍSTICAS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La importancia de características indica cuánto contribuye cada variable a las predicciones del modelo.\n",
        "En RandomForestRegressor, esto se calcula automáticamente en base a cuánta “información” aporta cada variable al reducir el error.  \n",
        "Para comprobar que variables son las más relevantes, se debe ejecutar el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener la importancia de cada feature\n",
        "importancias = modelo.feature_importances_\n",
        "nombres_features = X.columns\n",
        "\n",
        "# Crear un DataFrame ordenado\n",
        "df_importancias = pd.DataFrame({\n",
        "    'Feature': nombres_features,\n",
        "    'Importancia': importancias\n",
        "}).sort_values(by='Importancia', ascending=True)\n",
        "\n",
        "# Gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(df_importancias['Feature'], df_importancias['Importancia'], color='skyblue')\n",
        "plt.xlabel('Importancia')\n",
        "plt.title('Importancia de cada Característica en el Modelo')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **12. CONCLUSIONES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se concluye en que el modelo obtenido cumple con el objetivo de brindar un precio estimado para un vehículo acorde al año, kilometraje, fabricante, modelo, kilometros por año, tipo de combustible, typo de carrocería, densidad de publicaciones por estado y tipo de transmisión.  \n",
        "\n",
        "También se concluye en que el modelo tiene unos parámetros de desempeño aceptables, pero mejorables. La fuente de datos no es de lo más fiable (Criglist) ya que existen muchos valores que no son obligatorios al momento de realizar una publicación.\n",
        "\n",
        "A modo de comclusión académica o de aprendizaje, cabe mencionar lo sustancialmente divertido que fue lograr un modelo que prediga el precio de un vehículo. Pude fusionar dos pasiones, la ciencia de datos con el mundo automotor.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "______________________________________________________________________________\n",
        "## **13. PRÓXIMAS LÍNEAS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Para mejorar el modelo se puede probar con otros algoritmos como ser XGBoost, que es un algortmo de Gradient Boosting o \"aumento de gradiente\". Teóricamente daría mejores resultados que RandomForest.  \n",
        "\n",
        "2. Para simplificar el modelo, se puede considerar eliminar las features transmission_encoded y state_density ya que no tienen una gran importancia en la minimización del error.  \n",
        "\n",
        "3. Investigar que otras caracterisitcas se podrían agregar para que el modelo sea mas preciso y completo.  \n",
        "\n",
        "4. Generar un codigo en python para ingresar, codificar y decodificar los valores de un nuevo vehículo pasado al modelo para que realice la detección de su precio."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
